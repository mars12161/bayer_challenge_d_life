{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ecbf1d",
   "metadata": {},
   "source": [
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#from sklearn.metrics import plot_roc_curve, roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay, auc\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls */**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6dc71",
   "metadata": {},
   "source": [
    "Import data-no headers and I left the index_col out so I would have a list of consecutive numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./breast+cancer+wisconsin+diagnostic/wdbc.data',  index_col= None, header = None, na_values='?')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a41a5",
   "metadata": {},
   "source": [
    "Took a look at the data.  Note there are no headers, I found in the names.data file a list of the columns.  I then renamed the columns per this list:\n",
    "\n",
    "There are ten real-valued features computed for each cell nucleus :\n",
    "\n",
    "1. radius (mean of distances from center to points on the perimeter)\n",
    "2. texture (standard deviation of gray-scale values)\n",
    "3. perimeter\n",
    "4. area\n",
    "5. smoothness (local variation in radius lengths)\n",
    "6. compactness (perimeter² / area — 1.0)\n",
    "7. concavity (severity of concave portions of the contour)\n",
    "8. concave points (number of concave portions of the contour)\n",
    "9. symmetry\n",
    "10. fractal dimension (“coastline approximation” — 1)\n",
    "\n",
    "The mean, standard error and “worst” or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave_points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave_points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave_points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "df.columns = names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e11a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data looks complete (no empty lines at end).\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aea18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=df[\"diagnosis\"].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06889b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = pd.factorize(df['diagnosis'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=df[\"diagnosis\"].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export factorised dataset so I can use in streamlit\n",
    "df.to_csv('dataset_factorised.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da38369",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd13c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have 569 records of patients with 32 columns of data provided.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d01d5",
   "metadata": {},
   "source": [
    "For EDA purposes, I will only use the mean values for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad906e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked to see if there were any data types needing \n",
    "#conversion or missing data. There shouldn't be any missing, \n",
    "#as it stated it was a complete dataset.  All are ok per below.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab533e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking for unique values, there are 569 unique id #'s\n",
    "#and other measurements are mostly unique as expected.\n",
    "unique = df.nunique()\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicated patient info.  There isn't any to deal with.\n",
    "duplications = df.duplicated().sum()\n",
    "duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25757f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the data into 2 classes\n",
    "Malignant=df[df['diagnosis'] == 0]\n",
    "Benign=df[df['diagnosis'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide feature names into groups\n",
    "mean_features= ['radius_mean','texture_mean','perimeter_mean',\\\n",
    "                'area_mean','smoothness_mean','compactness_mean',\\\n",
    "                'concavity_mean','concave_points_mean','symmetry_mean',\\\n",
    "                'fractal_dimension_mean']\n",
    "error_features=['radius_se','texture_se','perimeter_se',\\\n",
    "                'area_se','smoothness_se','compactness_se',\\\n",
    "                'concavity_se','concave_points_se','symmetry_se',\\\n",
    "                'fractal_dimension_se']\n",
    "worst_features=['radius_worst','texture_worst','perimeter_worst',\\\n",
    "                'area_worst','smoothness_worst','compactness_worst',\\\n",
    "                'concavity_worst','concave_points_worst',\\\n",
    "                'symmetry_worst','fractal_dimension_worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df[['diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave_points_mean','symmetry_mean','fractal_dimension_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f7641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#There is a clear pattern between malignant and benign (2 clear clusters). \n",
    "sns.pairplot(df_mean, hue='diagnosis', markers=[\"o\", \"s\"])\n",
    "#Benign is orange, malignant is blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8293c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 20\n",
    "def histplot(features):\n",
    "  plt.figure(figsize=(10,15))\n",
    "  for i, feature in enumerate(features):\n",
    "      plt.subplot(5, 2, i+1)  #subplot function: the number of rows are given as 5 and number of columns as 2, the value i+1 gives the subplot number\n",
    "      sns.histplot(Malignant[feature], bins=bins, color='red', alpha=0.7, label='Malignant');\n",
    "      sns.histplot(Benign[feature], bins=bins, color='blue', alpha=0.7, label='Benign');\n",
    "      plt.title(str(' Density Plot of: ')+str(feature))\n",
    "      plt.xlabel(str(feature))\n",
    "      plt.ylabel('Count')\n",
    "      plt.legend(loc='upper right')\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "histplot(mean_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mean_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653e93b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[error_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eeec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby('diagnosis')['area_mean'].mean()\n",
    "df_count.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c021d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[worst_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf8e33",
   "metadata": {},
   "source": [
    "## Correlation/Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fd488",
   "metadata": {},
   "source": [
    "This is a heatmap of the above information that makes it easier to see the features\n",
    "that correlate with each other.  As you can see, there are many potential correlations \n",
    "to explore.  The highest at .99 are: \n",
    "- radius_mean : area_mean, and\n",
    "- perimeter_mean : area_mean. \n",
    "\n",
    "I would be curious to run a feature optimization on the data to see if it has similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.drop(columns = ['id'])\n",
    "plt.figure(figsize = (25,25))\n",
    "sns.heatmap(df_corr.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329221f",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "The columns that are the lightest indicate the greatest correlation with diagnosis.  I will be using all these columns to predict our result and try feature optimisation as well and eliminate categories to see if the accuracy improves!\n",
    "\n",
    "**Assumptions:**\n",
    "Perimeter, radius, and area can be similar measurements, if it is a large area, it will most likely have a large perimeter and large radius. I will use area for the EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d8c7e",
   "metadata": {},
   "source": [
    "# Define X and Y and split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60224a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id','diagnosis'], axis = 1)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .20, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a111bc9",
   "metadata": {},
   "source": [
    "I will run a Random Forest Classification Model as my baseline and then I will do a Logistic Regression Model with feature optimisation to see if I can get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b59b6",
   "metadata": {},
   "source": [
    "# Random Forest Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7891a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfc = X_train\n",
    "y_train_rfc = y_train\n",
    "X_test_rfc = X_test\n",
    "y_test_rfc = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd76b637",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bbb72e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#OOB (out-of-bag) score is a performance metric that uses\n",
    "#the samples that are not used in the training of the model, \n",
    "#which is called out-of-bag samples.\n",
    "rfc = RandomForestClassifier(n_estimators=40, max_depth=4)#, oob_score=True) \n",
    "rfc.fit(X_train_rfc, y_train_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeed8d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#rfc.oob_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc77d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_rfc_train = rfc.predict(X_train_rfc)\n",
    "y_pred_rfc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5c5ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy_rfc_train = round(rfc.score(X_train_rfc, y_train_rfc),3)\n",
    "accuracy_rfc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b1aa1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Feature Importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b4c15",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "importance = rfc.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,   v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd02c3f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e47a8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(confusion):\n",
    "    \n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(confusion,\n",
    "                xticklabels = np.unique(y),\n",
    "                yticklabels = np.unique(y),\n",
    "                cmap = 'RdPu',\n",
    "                annot=True,\n",
    "                fmt='g'\n",
    "                )\n",
    "\n",
    "    # fmt is used to switch off scientific notation\n",
    "    plt.xlabel('Predicted', fontsize=14)\n",
    "    plt.ylabel('Actual', fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b4571",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conf_train = confusion_matrix(y_train_rfc, y_pred_rfc_train)\n",
    "plot_heatmap(conf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a5455",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_rfc = rfc.predict(X_test_rfc)\n",
    "y_pred_test_rfc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5175cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rfc_test = round(rfc.score(X_test_rfc, y_test_rfc),3)\n",
    "accuracy_rfc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_test_rfc = confusion_matrix(y_test_rfc, y_pred_test_rfc)\n",
    "plot_heatmap(conf_test_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e13f6b",
   "metadata": {},
   "source": [
    "## Total Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_total_rfc = rfc.predict(X)\n",
    "y_pred_total_rfc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of trained model\n",
    "accuracy_rfc_total = rfc.score(X,y)\n",
    "accuracy_rfc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64328e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_rfc = round(accuracy_rfc_total,3)\n",
    "precision_rfc = round(precision_score(y, y_pred_total_rfc),3) \n",
    "recall_rfc = round(recall_score(y, y_pred_total_rfc),3)\n",
    "f1_rfc = round(f1_score(y, y_pred_total_rfc),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"The Random Forest Model has achieved:\"\"\")\n",
    "results_rfc = pd.DataFrame({\n",
    "    'Score': ['accuracy', 'precision', 'recall', 'f1'], \n",
    "    'Results': [accuracy_rfc, precision_rfc, recall_rfc, f1_rfc ]})\n",
    "results_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = number of cross validation datasets, k-folds\n",
    "cross_accuracy_log_rfc = cross_val_score(rfc, X_train_rfc,\n",
    "    y_train_rfc, cv = 5 , scoring = 'accuracy')\n",
    "\n",
    "CAL_rfc = np.round_(cross_accuracy_log_rfc, 2)\n",
    "CAL_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59268023",
   "metadata": {},
   "source": [
    "# Total RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e739a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc_total = rfc.predict(X)\n",
    "y_pred_rfc_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7335d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rfc_total = round(rfc.score(X, y),3)\n",
    "accuracy_rfc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18989ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_rfc_total = confusion_matrix(y, y_pred_rfc_total)\n",
    "plot_heatmap(conf_rfc_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48ab57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459f22dd",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lr = X_train\n",
    "y_train_lr = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750eb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear') \n",
    "lr.fit(X_train_lr,y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lr = lr.score(X_train_lr,y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c633d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"The Logistic Regression Model has achieved an:\n",
    "accuracy_lr = {round(accuracy_lr,3)}\n",
    "precision_lr = {round(precision_score(y_train_lr, y_pred_lr),3)} \n",
    "recall_lr = {round(recall_score(y_train_lr, y_pred_lr),3)}\n",
    "f1_lr = {round(f1_score(y_train_lr, y_pred_lr),3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_lr = lr.predict(X)\n",
    "ConfusionMatrixDisplay.from_predictions(y, ypred_lr, normalize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bff249",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svm = X_train\n",
    "y_train_svm = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa18ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(decision_function_shape='ovo', probability=True)\n",
    "svm.fit(X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ce949",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm = svm.score(X_train_svm,y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f886611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"The Support Vector Machine Model has achieved an:\n",
    "accuracy_svm = {round(accuracy_svm,3)}\n",
    "precision_svm = {round(precision_score(y_train_svm, y_pred_svm),3)} \n",
    "recall_svm = {round(recall_score(y_train_svm, y_pred_svm),3)}\n",
    "f1_svm = {round(f1_score(y_train_svm, y_pred_svm),3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_svm = svm.predict(X)\n",
    "ConfusionMatrixDisplay.from_predictions(y, ypred_svm, normalize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db4f38",
   "metadata": {},
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2caaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_em = X_train\n",
    "y_train_em = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          ('logreg', LogisticRegression(solver='liblinear')),\n",
    "          ('tree', DecisionTreeClassifier()),\n",
    "          ('svm', SVC(kernel='rbf', probability=True))\n",
    "]\n",
    "em = VotingClassifier(models, voting = 'soft')\n",
    "\n",
    "em.fit(X_train_em, y_train_em)\n",
    "accuracy_em = em.score(X_train_em, y_train_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_em = em.predict(X_train_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457481cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"The Ensemble Model has achieved an:\n",
    "accuracy_em = {round(accuracy_em,3)}\n",
    "precision_em = {round(precision_score(y_train_em, y_pred_em),3)} \n",
    "recall_em = {round(recall_score(y_train_em, y_pred_em),3)}\n",
    "f1_em = {round(f1_score(y_train_em, y_pred_em),3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4383aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_em = em.predict(X)\n",
    "ConfusionMatrixDisplay.from_predictions(y, ypred_em, normalize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d4516",
   "metadata": {},
   "source": [
    "## ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ed136",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"Random Forest Classification, AUC=\"+str(auc))\n",
    "\n",
    "y_pred = lr.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "\n",
    "y_pred = svm.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"Support Vector Machine, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "y_pred = em.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label=\"Ensemble Model, AUC=\"+str(auc))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f428434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c44f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning] *",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "192px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
